{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo:\n",
    "- Fix scrapper exception bug\n",
    "- Loop through users if fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import subprocess\n",
    "import names\n",
    "from selenium.webdriver.common.by import By\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_profile(name,count):\n",
    "    try:\n",
    "        command = \"instagram-scraper \" + name + \" -u maskradiogreece@gmail.com -p code12345 -t image -m \" + str(count) + \" --media-metadata\"\n",
    "        subprocess.check_output(command)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Exception occured scrapping profile of user {name}\")\n",
    "        raise Exception(\"Sorry, papala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_profile(folder_name):\n",
    "    print(\"Opening file\")\n",
    "    file = open(f'./{folder_name}/{folder_name}.json', encoding=\"utf8\")\n",
    "    print(\"Loading json\")\n",
    "    data = json.load(file)\n",
    "    pattern = re.compile(r'\\d+_\\d+_\\d+_n.jpg')\n",
    "    images = []\n",
    "    likes = []\n",
    "    for item in data[\"GraphImages\"]:\n",
    "        finds = re.search(pattern,item[\"display_url\"])\n",
    "        # If the post is at least 2 days old then add it to data or else skip it\n",
    "        if (datetime.today() - datetime.fromtimestamp(item[\"taken_at_timestamp\"])).days > 2:\n",
    "            images.append(finds[0])\n",
    "            likes.append(item[\"edge_media_preview_like\"][\"count\"])\n",
    "    maxLikes = max(likes)\n",
    "    if maxLikes < 1000:\n",
    "        print(f\"Not enough likes deleting {folder_name}\")\n",
    "        file.close()\n",
    "        print(\"Removing Folder\")\n",
    "        shutil.rmtree(rf\"./{folder_name}/\") #removes the folder.\n",
    "        print(\"Returning\")\n",
    "        return False\n",
    "    for index,name in enumerate(images):\n",
    "        try:\n",
    "            os.rename(rf\"./{folder_name}/{name}\",rf\"./{folder_name}/{round(likes[index]/maxLikes,2):.2f} {folder_name}{name}\")\n",
    "        except:\n",
    "            pass\n",
    "    print(\"Closing File\")\n",
    "    file.close()\n",
    "    print(\"Moving Folder\")\n",
    "    shutil.move(f\"./{folder_name}/\",f\"./Images/{folder_name}/\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Chrome Driver for Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"./chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.instagram.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To continue make sure that:\n",
    "- You logged in with your credentials\n",
    "- Accepted cookies\n",
    "- Then run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to start page\n",
      "Length of list is 56\n",
      "Getting 51 from darlenejanesummers\n",
      "Evaluating images on darlenejanesummers folder\n",
      "Opening file\n",
      "There was error on getting darlenejanesummers\n",
      "Going to sleep for 66s\n",
      "Getting 18 from darlene_sid_official\n",
      "Evaluating images on darlene_sid_official folder\n",
      "Opening file\n",
      "There was error on getting darlene_sid_official\n",
      "Going to sleep for 133s\n",
      "Getting 173 from darlene_goodman\n",
      "Evaluating images on darlene_goodman folder\n",
      "Opening file\n",
      "There was error on getting darlene_goodman\n",
      "Going to sleep for 232s\n"
     ]
    }
   ],
   "source": [
    "num_images = 0\n",
    "throttle = 60\n",
    "while True:\n",
    "    print(\"Going to start page\")\n",
    "    driver.get(\"https://www.instagram.com/\")\n",
    "    inputs = driver.find_elements_by_tag_name(\"input\")\n",
    "    # The 3rd one is the search \n",
    "    search = inputs[2]\n",
    "    random_female_name = names.get_first_name(gender='female') \n",
    "    search.send_keys(random_female_name)\n",
    "    time.sleep(4)\n",
    "    # Get List of Users\n",
    "    list = driver.find_elements(By.XPATH, '//div[@role=\"none\"]')\n",
    "    print(\"Length of list is\",len(list))\n",
    "    # Create List \n",
    "    profile_links = []\n",
    "    for user in list:\n",
    "        link = user.find_element_by_tag_name(\"a\")\n",
    "        link = link.get_attribute(\"href\")\n",
    "        if link.find(\"explore\") == -1:\n",
    "            profile_links.append(link)\n",
    "    searched_links = pd.read_csv(\"./Links.csv\")\n",
    "    searched_links = searched_links[\"Links\"].to_list()\n",
    "    for link in profile_links:\n",
    "        if link in searched_links:\n",
    "            continue\n",
    "        driver.get(link);\n",
    "        time.sleep(random.randint(1,5))\n",
    "        try:\n",
    "            is_private = driver.find_element(By.XPATH, \"//*[text()[contains(., 'Αυτός ο λογαριασμός είναι ιδιωτικός')]]\" )\n",
    "            continue \n",
    "        except: \n",
    "            name = link.split(\"/\")[3]\n",
    "            post = driver.find_element(By.XPATH, \"//*[text()[contains(., 'δημοσιεύσεις') or contains(., 'δημοσίευση')]]\" )\n",
    "            post.find_element_by_tag_name(\"span\")\n",
    "            num_posts = int(post.find_element_by_tag_name(\"span\").get_attribute(\"innerHTML\").replace(\",\",\"\"))\n",
    "            if num_posts < 10:\n",
    "                continue\n",
    "            get_num_posts = math.floor(num_posts * 0.5)\n",
    "            get_num_posts = min(math.floor(num_posts * 0.5),200)\n",
    "            print(f\"Getting {get_num_posts} from {name}\")\n",
    "            try:\n",
    "                scrap_profile(name,get_num_posts)\n",
    "                print(f\"Evaluating images on {name} folder\")\n",
    "                added = evaluate_profile(name)\n",
    "                if added:\n",
    "                    num_images += get_num_posts\n",
    "                    print(f\"Got {num_images} in total\")\n",
    "            except:\n",
    "                print(f\"There was error on getting {name}\")\n",
    "                # Sleep bettwen throttle to throttle + 2 minutes\n",
    "                # We get throttling from API\n",
    "                sleep_time = random.randint(throttle, throttle + 60)\n",
    "                print(f\"Going to sleep for {sleep_time}s\")\n",
    "                time.sleep(sleep_time)\n",
    "                # Increase throttle by 1 min\n",
    "                throttle += 60\n",
    "                # Append Failed Link to end of array to try and fetch again \n",
    "                profile_links.append(link)\n",
    "                continue\n",
    "            searched_links.append(link)\n",
    "            df = pd.DataFrame(searched_links,columns=[\"Links\"])\n",
    "            df.to_csv('./Links.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
